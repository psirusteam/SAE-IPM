---
title: "Metodología bayesiana de estimación desagregada para cualquier IPM ($IPM = H \\times A$)"
author: "Andrés Gutierrez, Stalyn Guerrero."
format: html
---

## Introducción

El Índice de Pobreza Multidimensional (IPM) es una medida de la pobreza que toma en cuenta múltiples dimensiones de la vida humana, como la salud, la educación, el acceso a los servicios básicos y las condiciones de vida. Fue desarrollado por Sabina Alkire y James Foster en 2007, y se ha utilizado para medir la pobreza en más de 100 países.

El IPM es importante porque ofrece una visión más completa de la pobreza que las medidas tradicionales de la pobreza, que se basan en el ingreso o el consumo. El IPM permite identificar a las personas que son pobres en múltiples dimensiones, y proporciona información sobre las dimensiones de la pobreza que más impactan en la vida de las personas.

El IPM tiene algunas limitaciones. Una limitación es que es difícil de calcular, ya que requiere datos sobre múltiples dimensiones de la pobreza. Otra limitación es que el IPM puede ser subjetivo, ya que depende de las dimensiones que se incluyen en el índice y de los pesos que se asignan a cada dimensión.

En los últimos años, se han desarrollado metodologías más recientes para el cálculo del IPM. Estas metodologías tienen en cuenta algunas de las limitaciones del IPM tradicional, y ofrecen una visión más precisa de la pobreza multidimensional.

Una de las metodologías más recientes es el IPM de Alkire-Foster-Sen (Alkire, Foster y Sen, 2010). Este índice es similar al IPM tradicional, pero tiene en cuenta la desigualdad entre las personas que son pobres. El IPM de Alkire-Foster-Sen también permite identificar a las personas que son pobres en una dimensión, pero no en otras.

El IPM es una herramienta importante para medir la pobreza multidimensional. Ofrece una visión más completa de la pobreza que las medidas tradicionales de la pobreza, y proporciona información sobre las dimensiones de la pobreza que más impactan en la vida de las personas. En los últimos años, se han desarrollado metodologías más recientes para el cálculo del IPM, que ofrecen una visión más precisa de la pobreza multidimensional.

## Índice de Pobreza Multidimensional

El Índice de Pobreza Multidimensional (IPM) es una medida que captura la pobreza desde múltiples dimensiones. Se calcula utilizando ponderaciones y umbrales en función de diferentes variables o indicadores que reflejan aspectos diversos de la calidad de vida.Los componentes del IPM de describen a continuación:  

1.    Headcount Ratio (H)

   Este componente mide la proporción de personas que están privadas en al menos una de las dimensiones consideradas. Matemáticamente, $H$ se calcula como la proporción entre el número de personas privadas y la población total:
$$
      H = \frac{1}{N} \sum_{i=1}^{N} I\left( q_{i} > z \right)
$$
con 
$$
      q_i =  \sum_{k=1}^{K} w_k \cdot y_{i}^{k}  
$$

Donde:

  -   $N$ es el número de individuos u hogares en la población. 
  -   $K$ es el número de dimensiones o indicadores de la privación.
  -   $w_k$ es el ponderador asociado a la dimensión $k$.
  -   $y_{i}^{k}$ es una variable binaria que toma el valor $1$ si el individuo $i$ esta privado  en la dimensión $k$ y $0$ en el caso contrario. 
  -   $z$ es el umbral para considerar a alguien con multiples privaciones.
  
 

2.    Intensity of Deprivation (A) 

Este componente mide la intensidad o gravedad promedio de la privación entre aquellos que están privados. Matemáticamente, $A$ se calcula como el promedio de los indicadoras $y_{i}^{k}$ para aquellos hogares o personas que están privados:   
  
$$ 
A  = \frac{1}{N} \sum_{i=1}^{N} \bar{q_i} = \frac{1}{NK} \sum_{i=1}^{N} \sum_{k=1}^{K} q_i 
$$

Luego, el Índice de Pobreza Multidimensional (IPM) se expresa como:

$$
IPM = H \times A
$$
reemplazando las $H$ y $A$ por sus respectivas ecuaciones se tiene que: 

$$
IPM =\left[ \frac{1}{N} \sum_{i=1}^{N} I\left( q_{i} > z \right) \right] \left[  \frac{1}{NK} \sum_{i=1}^{N} \sum_{k=1}^{K} q_i  \right]
$$
de donde se sigue 

$$
IPM = \frac{1}{N^2K} \left[\sum_{i=1}^{N} I\left( q_{i} > z \right) \right] \left[ \sum_{i=1}^{N} \sum_{k=1}^{K} q_i  \right]
$$


El IPM combina los componentes $H$ y $A$. 

### Ejemplo  
Para ilustrar el cálculo del Índice de Pobreza Multidimensional (IPM), empleamos el conjunto de datos simulados a continuación.

Consideremos un escenario con diez observaciones ($N = 10$), a las cuales se les han asignado ocho dimensiones distintas ($K = 8$). Estas dimensiones están ponderadas de acuerdo con el vector $w = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2)$.

```{r}
# Definición de parámetros
K <- 8  # Número de dimensiones
N <- 10 # Número de personas
w <- c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2)  # Ponderaciones para cada dimensión
```

A continuación se realiza la simulación de la matriz de variables dicótomicas para las diez persona respondientes 

```{r}
set.seed(1234)
# Generación de datos simulados
M_dummy <- matrix(sample(x = c(1,0),size =  N * K, replace = TRUE),
                   nrow = N, ncol = K)  # Matriz de dimensiones aleatorias

colnames(M_dummy)<- paste0("y",1:K)
rownames(M_dummy)<- paste0("P",1:N)
```


```{r, echo=FALSE}
library(kableExtra)
x_html <- knitr::kable(M_dummy, "html")
kable_styling(x_html, "striped", position = "left", font_size = 15)
```

A continuación se realiza el calculo de H y A usando las ecuaciones dadas previamente. 
```{r, eval=TRUE}
# Cálculo de H y A utilizando el vector q
q <- M_dummy %*% w  # Vector q de ponderaciones por dimensiones
Indicadora <- ifelse(q > 0.4,1,0)
datos <- data.frame(M_dummy, q = q, Indicadora) 
```

```{r, echo=FALSE}
x_html <- knitr::kable(datos, "html")
kable_styling(x_html, "striped", position = "left", font_size = 15)
```

Para obtener la primera parte de la ecuación hacemos la suma de la indicadora, es decir:  
```{r, eval=TRUE}
D <- sum(Indicadora)
D
```
El segundo elemento del IPM se obtiene al sumar los $q_i$ 

```{r, eval=TRUE}
Q <- sum(q)
Q
```
Luego, el IPM se obtiene como: 

```{r, eval=TRUE}
IPM <- (D * Q)/((N^2)*K)  # Cálculo del IPM
IPM
```

##  Estimación del modelo de unidad para variables Binarias

En muchas aplicaciones, la variable de interés en áreas pequeñas puede ser binaria, por ejemplo, $y_{di} = 0$ ó 1, representando la ausencia (o no) de una característica específica. En el caso binario, la estimación objetivo en cada dominio $d = 1, \dotso, D$ puede ser la proporción $\bar{Y}_d = \pi_d = \frac{1}{N_d} \sum_{i=1}^{N_d} y_{di}$ de la población que tiene esta característica, donde $N=\sum_{d=1}^{D}N_d$,   $\pi_{di}$ es la probabilidad de que una unidad específica $i$ en el dominio $d$ obtenga el valor 1.

Aunque se han propuesto otros métodos para resultados binarios, como el modelado basado en M-cuantiles (Chambers et al., 2016), en esta aplicación seguimos el enfoque tradicional basado en modelos mixtos lineales generalizados. En este escenario, $\pi_{di}$ se modela con una función de enlace logit definida como:

$$
\text{logit}(\pi_{di}) = \log \left( \frac{\pi_{di}}{1 - \pi_{di}} \right) = \eta_{di} = \mathbf{x}_{di}^\top \mathbf{\beta} + u_d 
$$


con $i = 1, \ldots, N_d$, $d = 1, \ldots, D$, $\boldsymbol{\beta}$ un vector de parámetros de efectos fijos y $u_d$ el efecto aleatorio específico del área para el dominio $d$ con $u_d \sim N(0, \sigma_u^2)$. Se asume que $u_d$ son independientes y $y_{di} | u_d \sim \text{Bernoulli}(\pi_{di})$ con $E(y_{di} | u_d) = \pi_{di}$ y $\text{Var}(y_{di} | u_d) = \sigma^2_{di} = \pi_{di} (1 - \pi_{di})$. Además, $\mathbf{x}_{di}$ representa el vector $p \times 1$ de valores de las variables auxiliares a nivel de unidad.

Dado que nuestro problema involucra la identificación de privaciones en forma de valores binarios $(0,1)$ en relación con varios indicadores, hemos optado por utilizar un modelo mixto logit Bernoulli a nivel de unidad como punto de partida. Hay varios algoritmos para ajustar este tipo de modelo, incluyendo el método de momentos simulados (MSM), el algoritmo de expectación-maximización (EM), el algoritmo de verosimilitud cuasi-penalizada (PQL) y el algoritmo de aproximación de máxima verosimilitud Laplace (ML-Laplace). 

Encontrar estimaciones de alta calidad en dominios pequeños puede ser difícil cuando no hay muchos datos de esos dominios o cuando el tamaño de la muestra es demasiado pequeño para producir resultados confiables. Para abordar este problema, se ha propuesto la idea de un Predictor Empírico Óptimo (EBP). El EBP se puede aplicar a cantidades de interés como probabilidades, sumas de probabilidades y proporciones en diferentes dominios. Puede aproximarse utilizando técnicas de simulación de Monte Carlo, pero esto puede ser difícil en la práctica. En cambio, se puede usar un predictor "plug-in" para $\pi_{di}$ que se define como:

$$
\hat{\pi}_{di} = \frac{\exp(\mathbf{x}_{di}^\top \hat{\boldsymbol{\beta}} + \hat{u}_d)}{1 + \exp(\mathbf{x}_{di}^\top \hat{\boldsymbol{\beta}} + \hat{u}_d)}
$$

Donde $\hat{\boldsymbol{\beta}}$ es la estimación del vector de parámetros de efectos fijos y $\hat{u}_d$ es la estimación del efecto aleatorio específico del área para el dominio $d$. Esta expresión permitiría obtener el predictor "plug-in" de $\bar{Y}_d$:

$$
\hat{\bar{Y}}^{in}_d = \frac{1}{N_d}(\sum _{i \in s_d}y_{di} + \sum _{i \in s_d} \hat{\pi}_{di}^{in})
$$


El predictor "plug-in" es más fácil de implementar que el EBP, pero no siempre es tan preciso. La elección de qué predictor usar depende de la situación específica.

Los métodos bayesianos también se pueden utilizar para ajustar modelos mixtos logit Bernoulli. Uno de los métodos más comunes es el algoritmo de Markov Chain Monte Carlo (MCMC). Este algoritmo genera muestras de los parámetros del modelo a partir de su distribución posterior, que es la distribución de los parámetros dada la evidencia.

Otro método bayesiano para ajustar modelos mixtos logit Bernoulli es el enfoque de máxima verosimilitud aproximada (MAP). Este enfoque se basa en la idea de encontrar los parámetros del modelo que maximizan la verosimilitud de los datos, suponiendo que los parámetros siguen una distribución a priori.

Los métodos bayesianos tienen varias ventajas sobre los métodos clásicos para ajustar modelos mixtos logit Bernoulli. En primer lugar, los métodos bayesianos pueden incorporar información previa sobre los parámetros del modelo, lo que puede mejorar la precisión de las estimaciones. En segundo lugar, los métodos bayesianos pueden proporcionar intervalos de confianza para los parámetros del modelo, que pueden ser utilizados para hacer inferencias sobre el modelo. En tercer lugar, los métodos bayesianos pueden ser utilizados para generar predicciones del modelo, que pueden ser utilizadas para tomar decisiones.

Sin embargo, los métodos bayesianos también tienen algunas desventajas. Por ejemplo, los métodos bayesianos pueden ser más sensibles a la elección de la distribución a previas, lo que puede dificultar la obtención de estimaciones precisas. Para evitar, eso en nuestro ejercico se hara uso de distribuciones previas no informativas. 

